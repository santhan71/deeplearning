{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_PA11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santhan71/deeplearning/blob/master/DL_PA11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEC3BNuxJf2J",
        "colab_type": "text"
      },
      "source": [
        "                                                                    Deep learning assignment(PA_1)\n",
        "                                                                          ROLL NO: EE19S001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGrmd3LOKLvx",
        "colab_type": "text"
      },
      "source": [
        "     The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.\n",
        "     The MNIST database contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. There have been a number of scientific papers on attempts to achieve the lowest error rate; one paper, using a hierarchical system of convolutional neural networks, manages to get an error rate on the MNIST database of 0.23%. The original creators of the database keep a list of some of the methods tested on it. In their original paper, they use a support-vector machine to get an error rate of 0.8%. An extended dataset similar to MNIST called EMNIST has been published in 2017, which contains 240,000 training images, and 40,000 testing images of handwritten digits and characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaSYSL-9J-cs",
        "colab_type": "text"
      },
      "source": [
        "      IN this assignemnt code,I am extracting only 1000 sample of training data set and 100 images from test data set\n",
        "              "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aArvkqhsPaTe",
        "colab_type": "text"
      },
      "source": [
        "        Importing required libraries for the programme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-i6lDt8HRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H28Om45OPyOb",
        "colab_type": "text"
      },
      "source": [
        "   Download  the MNIST  training and testing data and load  the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryyMtJOi_TOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "\n",
        "testset =torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                        download=True, transform= transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset)\n",
        "testloader = torch.utils.data.DataLoader(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd8mD30IJb5a",
        "colab_type": "text"
      },
      "source": [
        "       Crop the given train and test data set to 1000 and 100 dataset and the get the labels of each data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhoYHf2NABfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_list = []\n",
        "for i in range(1000):\n",
        "    train_list.append(trainset[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGF15yrWwPV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = []\n",
        "for i in range(1000):\n",
        "    train_labels.append(trainset[i][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR_iE1yUheAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47fa3b45-d0b3-4f68-94a4-38e8f8638c30"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-js5ZQgwago",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_labels))\n",
        "print(trainset[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVdtkwogAp68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_list = []\n",
        "for i in range(100):\n",
        "    test_list.append(testset[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrev9WfiwhAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = []\n",
        "for i in range(100):\n",
        "    test_labels.append(testset[i][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w9laDyGxmi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c8ddf782-2770-4dc6-d14b-7d8b264690de"
      },
      "source": [
        "print(test_labels)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF0Whj0CFZ8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainload_1 = torch.utils.data.DataLoader(train_list)\n",
        "testload_2= torch.utils.data.DataLoader(test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9qhogXH_UOt4",
        "colab": {}
      },
      "source": [
        "train_list1=[]\n",
        "for i in range(1000):\n",
        "  train_list1.append(train_list[i][0][0].view(1,-1))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TNuMnnGYPdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_list1=[]\n",
        "for i in range(100):\n",
        "  test_list1.append(test_list[i][0][0].view(1,-1))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwk3YhEkTKfR",
        "colab_type": "text"
      },
      "source": [
        "     * Code for k=1 *(find the eculidian dustance and sorting them in increasing order)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGQJrIDlfmoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_result = []\n",
        "list_resultsort = []\n",
        "x = torch.FloatTensor(100,1000)\n",
        "for i in range(100):\n",
        "  temp_list = []\n",
        "  for j in range(1000):\n",
        "    d1=abs((test_list1[i])**2-(train_list1[j])**2)\n",
        "    dist = torch.sqrt(torch.sum(d1))\n",
        "    #temp2_list = np.sort(d2.numpy())\n",
        "    temp_list.append(dist)\n",
        "  list_result.append(np.array(temp_list))\n",
        "  list_resultsort.append(np.sort(np.array(temp_list)))\n",
        "list_result = np.array(list_result)\n",
        "list_resultsort = np.array(list_resultsort)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4rdZunNiSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0803a93-56ee-4291-a1d6-9d5369bd366a"
      },
      "source": [
        "print(list_result.shape)\n",
        "#print(list_result[1])\n",
        "#print(np.array(list_result[1]))\n"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ALPHqH13Thx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cf6ce1b-5056-497f-b05d-44487b880e64"
      },
      "source": [
        "print(list_resultsort.shape) "
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y5GEmXiT6ZM",
        "colab_type": "text"
      },
      "source": [
        "  Getting the labels of minimmum distance and comparing it with the test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Kbr-7Zz_2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100):\n",
        " # print(np.min(list_resultsort[i]))\n",
        "  print(np.where(list_result[i]==list_resultsort[i][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbfAaijr6W6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100):\n",
        "  index = np.where(list_result[i]==list_resultsort[i][0])\n",
        "  print(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2FT5YsFF4UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_list = []\n",
        "for i in range(100):\n",
        "  print(np.where(list_result[i]==np.min(list_resultsort[i])))\n",
        "  print(train_labels[np.where(list_result[i]==np.min(list_resultsort[i]))[0][0]])\n",
        "  x_list.append(train_labels[np.where(list_result[i]==np.min(list_resultsort[i]))[0][0]])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgdRCOg6KDAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1cadf2d0-75c2-4bb8-fcb5-a7fcefa88ebe"
      },
      "source": [
        "print(x_list)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 2, 1, 0, 4, 1, 9, 9, 4, 9, 0, 8, 9, 0, 1, 3, 9, 7, 3, 4, 9, 6, 1, 5, 4, 0, 7, 9, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 1, 1, 1, 7, 4, 1, 5, 5, 1, 8, 4, 4, 6, 3, 5, 5, 0, 0, 4, 1, 9, 1, 7, 2, 9, 9, 7, 4, 8, 4, 3, 0, 7, 0, 0, 7, 1, 7, 3, 3, 9, 7, 9, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 9, 1, 7, 6, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYTsZRXRUsgo",
        "colab_type": "text"
      },
      "source": [
        "FInidng the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nBUCYa8OssU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b94ff154-e446-41db-83d1-94a90267cb07"
      },
      "source": [
        "\n",
        "c=0\n",
        "for i in range(100):\n",
        "  if(x_list[i] == test_labels[i]):\n",
        "    c=c+1\n",
        "  \n",
        "    \n",
        "print(c)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKSB21_hVEnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh266FKcVR00",
        "colab_type": "text"
      },
      "source": [
        "      k-NN classifier for k=3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-netyd2Pjrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93782437-12a6-4734-a291-4651345e9b90"
      },
      "source": [
        "list_result[1].argsort()[:3]"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([360, 602, 274])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU2dBtr3Vj9o",
        "colab_type": "text"
      },
      "source": [
        "      Here we are trying to get the top 3 minimum dstance elements to the given data set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM3CAsGeeVC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_result1 = []\n",
        "for i in range(100):\n",
        "  temp_list = []\n",
        "  for j in range(1000):\n",
        "    d1=abs((test_list1[i])**2-(train_list1[j])**2)\n",
        "    dist = torch.sqrt(torch.sum(d1))\n",
        "    #temp2_list = np.sort(d2.numpy())\n",
        "    temp_list.append(dist)\n",
        "  list_result1.append(np.array(temp_list).argsort()[:3])\n",
        "#list_result = np.array(list_result)\n",
        "\n",
        "print(list_result1)\n",
        "print(len(list_result1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy-A_nLRfgNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_list1 = []\n",
        "for i in range(100):\n",
        "  x_list1.append([train_labels[z] for z in list_result1[i]])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mr9vZaAlIx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_list1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugah7DvXgNLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VriNk5BhWG1D",
        "colab_type": "text"
      },
      "source": [
        "   counting the repeated numbers in the array ,if not possible  minimum distance label for 3 diffrent  classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xzSKxLrrWZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_list = []\n",
        "for i in range(100):\n",
        "  x_list1[i]\n",
        "  final_list.append(Counter(x_list1[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JeFbkUotW_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e9768b3a-3f0c-40f8-ccd8-af8242d988a3"
      },
      "source": [
        " print(final_list)  "
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Counter({7: 3}), Counter({2: 1, 8: 1, 6: 1}), Counter({1: 3}), Counter({0: 3}), Counter({9: 2, 4: 1}), Counter({1: 3}), Counter({4: 2, 9: 1}), Counter({9: 2, 4: 1}), Counter({4: 1, 6: 1, 9: 1}), Counter({7: 2, 9: 1}), Counter({0: 3}), Counter({6: 2, 8: 1}), Counter({9: 3}), Counter({0: 3}), Counter({1: 3}), Counter({3: 1, 5: 1, 9: 1}), Counter({9: 2, 4: 1}), Counter({7: 3}), Counter({3: 1, 5: 1, 2: 1}), Counter({9: 2, 4: 1}), Counter({9: 3}), Counter({6: 2, 0: 1}), Counter({1: 3}), Counter({5: 2, 4: 1}), Counter({4: 1, 9: 1, 5: 1}), Counter({0: 3}), Counter({7: 3}), Counter({9: 2, 4: 1}), Counter({0: 3}), Counter({1: 3}), Counter({3: 3}), Counter({1: 3}), Counter({3: 3}), Counter({4: 3}), Counter({7: 3}), Counter({2: 3}), Counter({7: 3}), Counter({1: 3}), Counter({1: 2, 2: 1}), Counter({1: 3}), Counter({1: 3}), Counter({7: 3}), Counter({4: 2, 9: 1}), Counter({1: 3}), Counter({5: 1, 1: 1, 3: 1}), Counter({5: 1, 6: 1, 3: 1}), Counter({1: 3}), Counter({8: 1, 4: 1, 2: 1}), Counter({4: 3}), Counter({4: 3}), Counter({6: 3}), Counter({3: 2, 5: 1}), Counter({5: 2, 4: 1}), Counter({5: 1, 0: 1, 4: 1}), Counter({0: 2, 6: 1}), Counter({0: 2, 5: 1}), Counter({4: 3}), Counter({1: 3}), Counter({9: 2, 4: 1}), Counter({1: 3}), Counter({7: 3}), Counter({8: 2, 2: 1}), Counter({9: 1, 7: 1, 4: 1}), Counter({9: 3}), Counter({7: 3}), Counter({4: 1, 7: 1, 5: 1}), Counter({8: 1, 1: 1, 2: 1}), Counter({4: 3}), Counter({3: 3}), Counter({0: 3}), Counter({7: 3}), Counter({0: 3}), Counter({2: 2, 0: 1}), Counter({7: 2, 9: 1}), Counter({1: 3}), Counter({7: 3}), Counter({3: 2, 6: 1}), Counter({3: 1, 2: 1, 7: 1}), Counter({9: 3}), Counter({7: 3}), Counter({9: 2, 7: 1}), Counter({6: 3}), Counter({2: 3}), Counter({7: 2, 9: 1}), Counter({8: 2, 9: 1}), Counter({4: 3}), Counter({7: 3}), Counter({3: 2, 9: 1}), Counter({6: 3}), Counter({1: 3}), Counter({3: 2, 5: 1}), Counter({6: 3}), Counter({9: 1, 4: 1, 7: 1}), Counter({3: 3}), Counter({1: 3}), Counter({9: 3}), Counter({1: 3}), Counter({1: 2, 7: 1}), Counter({6: 3}), Counter({9: 3})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph_F2FJ_2nzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "50ea6361-0309-4e66-9299-b3f8cd5dfe29"
      },
      "source": [
        "predictions = []\n",
        "for item in final_list:\n",
        "  predictions.append(list(item.keys())[0])\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 2, 1, 0, 4, 1, 9, 9, 4, 9, 0, 8, 9, 0, 1, 3, 9, 7, 3, 4, 9, 6, 1, 5, 4, 0, 7, 9, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 1, 1, 1, 7, 4, 1, 5, 5, 1, 8, 4, 4, 6, 3, 5, 5, 0, 0, 4, 1, 9, 1, 7, 2, 9, 9, 7, 4, 8, 4, 3, 0, 7, 0, 0, 7, 1, 7, 3, 3, 9, 7, 9, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 9, 1, 7, 6, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTL294ewWns0",
        "colab_type": "text"
      },
      "source": [
        "      Finding the accuarcy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ozpEwht5DKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75d526fe-6616-4e1e-9b9b-582839b7d549"
      },
      "source": [
        "y=0\n",
        "for i in range(100):\n",
        "  if(predictions[i] == test_labels[i]):\n",
        "    y=y+1\n",
        "  \n",
        "    \n",
        "print(y)"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxtaJ0ubWwoc",
        "colab_type": "text"
      },
      "source": [
        "           Plotting the confusion  matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnJ280r_tacR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "\n",
        "\n",
        "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = [classes[i] for i in unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "\n",
        "plot_confusion_matrix(test_labels,predictions, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnPkwDaJaxqA",
        "colab_type": "text"
      },
      "source": [
        "                         Simliar process for k=5  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDnz3UhiW2hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "be540a56-7103-4232-e344-b8aca0f5c14a"
      },
      "source": [
        "list_result2 = []\n",
        "for i in range(100):\n",
        "  temp_list = []\n",
        "  for j in range(1000):\n",
        "    d1=abs((test_list1[i])**2-(train_list1[j])**2)\n",
        "    dist = torch.sqrt(torch.sum(d1))\n",
        "    #temp2_list = np.sort(d2.numpy())\n",
        "    temp_list.append(dist)\n",
        "  list_result2.append(np.array(temp_list).argsort()[:5])\n",
        "#list_result = np.array(list_result)\n",
        "\n",
        "print(list_result2)\n",
        "print(len(list_result2))"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([773, 522, 962, 243, 868]), array([360, 602, 274,  50, 630]), array([604, 466, 276, 648, 290]), array([451, 320,  95, 192, 612]), array([914, 322, 940, 608, 804]), array([290, 466, 648, 604, 276]), array([ 54, 272, 372,  26, 413]), array([744, 754, 932, 212, 110]), array([237, 996, 782, 912, 450]), array([167, 703,  15, 337, 377]), array([524, 458,  88, 429, 118]), array([418, 488, 494, 270, 604]), array([362, 687, 116, 402, 369]), array([210, 612, 192, 326, 118]), array([678,  40, 638, 398, 780]), array([ 50, 316,  48, 998, 514]), array([334, 564, 322, 344, 914]), array([934, 868,  52, 371, 522]), array([ 30, 924,  76, 198, 650]), array([ 92, 580, 566, 812, 162]), array([423, 319,  57, 419, 471]), array([106, 232, 802, 660, 218]), array([604, 276, 310, 466, 454]), array([625, 912, 754, 420, 922]), array([ 92, 434, 778,  26, 682]), array([427, 399, 293, 462, 519]), array([686, 786, 820, 908, 196]), array([550, 344, 438, 194, 877]), array([320,  69, 662, 169,  95]), array([184, 358, 978,   8, 780]), array([ 74,  98, 130, 808, 856]), array([738,   8, 104, 184,   6]), array([136, 298,  74, 752,  98]), array([ 64, 828, 850, 481, 782]), array([795, 803, 839, 683, 853]), array([347, 457, 774, 317, 325]), array([ 84, 288, 798, 522, 904]), array([184, 780,   8, 618,  14]), array([270, 124, 472, 310, 674]), array([128, 450, 556,  40, 920]), array([ 72, 366, 484, 102, 454]), array([636, 258, 786,  96, 888]), array([372, 237, 744, 336,  26]), array([604, 510, 538, 276, 309]), array([132, 780, 808, 184, 922]), array([396, 660,  98, 420, 496]), array([870, 248,   6, 104, 738]), array([418, 754, 584, 604, 379]), array([438,  58, 194, 520, 877]), array([804, 164, 914, 322, 237]), array([ 62, 401, 816,  18, 672]), array([ 30, 486, 554, 890, 895]), array([396, 402, 474, 328, 687]), array([316, 210, 754, 604, 718]), array([108, 506, 464, 682, 418]), array([952, 690, 216,  69, 662]), array([914, 314, 194, 877, 692]), array([276, 604, 648, 174, 676]), array([116, 877, 550, 446, 763]), array([270, 466, 604, 124, 648]), array([686, 196, 214, 820, 908]), array([493, 923, 615, 929, 148]), array([304, 786, 354,  26, 754]), array([227,  19, 153, 423, 754]), array([567, 839, 651, 753, 723]), array([754, 786, 778, 304,  26]), array([418, 604, 472, 276, 454]), array([217, 289, 237, 804, 338]), array([ 74, 130, 840,  98, 752]), array([156, 260, 435, 489, 114]), array([562, 994, 522,  52, 371]), array([429, 283, 458, 435, 293]), array([869, 844, 696, 702, 866]), array([795, 803,  33, 137, 611]), array([102, 780,  14,  72, 618]), array([384,  42, 968,  96, 324]), array([ 98,  50, 630, 856, 136]), array([500, 268, 798, 422, 754]), array([ 19,  22, 153, 641, 423]), array([911, 880, 683, 505, 753]), array([812, 786, 428, 686, 576]), array([106, 816, 311, 151, 431]), array([684, 642, 213, 365, 308]), array([786, 686, 170, 304, 820]), array([532, 708, 282, 628, 144]), array([ 58, 877, 914, 692, 194]), array([773, 307, 880, 839, 168]), array([356, 808,  48,  74, 748]), array([762, 592, 534, 186, 536]), array([416, 290, 510, 105, 315]), array([ 98, 479, 768, 149, 836]), array([498, 431,  32, 816, 996]), array([ 22, 754, 586,  99, 601]), array([ 10,  74, 890, 130,  49]), array([200,   6, 248, 382, 406]), array([772, 806, 763, 834, 329]), array([870, 738, 104,   6, 978]), array([478, 920, 211, 370, 251]), array([106, 126, 238, 232,  18]), array([322, 334, 940, 914, 820])]\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6KyRcSKXHvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_list2 = []\n",
        "for i in range(100):\n",
        "  x_list2.append([train_labels[m] for m in list_result2[i]])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc_rwfvgXNPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_list1 = []\n",
        "for i in range(100):\n",
        "  x_list2[i]\n",
        "  final_list1.append(Counter(x_list2[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP3SZ3_DX_st",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9ac71998-5549-4d41-8815-e2a256809ef0"
      },
      "source": [
        "print(final_list1)"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Counter({7: 5}), Counter({6: 2, 2: 1, 8: 1, 3: 1}), Counter({1: 5}), Counter({0: 5}), Counter({4: 2, 9: 2, 7: 1}), Counter({1: 5}), Counter({4: 4, 9: 1}), Counter({9: 3, 4: 1, 7: 1}), Counter({4: 1, 6: 1, 9: 1, 5: 1, 1: 1}), Counter({7: 4, 9: 1}), Counter({0: 5}), Counter({6: 2, 1: 2, 8: 1}), Counter({9: 3, 4: 2}), Counter({0: 5}), Counter({1: 5}), Counter({3: 2, 5: 2, 9: 1}), Counter({9: 3, 4: 2}), Counter({7: 5}), Counter({3: 2, 2: 2, 5: 1}), Counter({9: 4, 4: 1}), Counter({9: 5}), Counter({6: 4, 0: 1}), Counter({1: 5}), Counter({5: 3, 4: 1, 6: 1}), Counter({4: 3, 9: 1, 5: 1}), Counter({0: 5}), Counter({7: 5}), Counter({4: 3, 9: 2}), Counter({0: 5}), Counter({1: 5}), Counter({3: 5}), Counter({1: 5}), Counter({3: 5}), Counter({4: 4, 9: 1}), Counter({7: 5}), Counter({2: 5}), Counter({7: 5}), Counter({1: 5}), Counter({1: 3, 2: 2}), Counter({1: 5}), Counter({1: 5}), Counter({7: 5}), Counter({4: 4, 9: 1}), Counter({1: 5}), Counter({1: 2, 5: 1, 3: 1, 6: 1}), Counter({5: 3, 6: 1, 3: 1}), Counter({1: 5}), Counter({4: 2, 8: 1, 2: 1, 1: 1}), Counter({4: 4, 9: 1}), Counter({4: 4, 9: 1}), Counter({6: 5}), Counter({3: 4, 5: 1}), Counter({5: 3, 4: 1, 9: 1}), Counter({4: 2, 5: 1, 0: 1, 1: 1}), Counter({0: 2, 6: 1, 4: 1, 8: 1}), Counter({0: 4, 5: 1}), Counter({4: 5}), Counter({1: 5}), Counter({9: 3, 4: 1, 7: 1}), Counter({1: 5}), Counter({7: 5}), Counter({8: 2, 2: 1, 9: 1, 7: 1}), Counter({4: 3, 9: 1, 7: 1}), Counter({9: 4, 4: 1}), Counter({7: 5}), Counter({4: 2, 7: 1, 5: 1, 9: 1}), Counter({1: 3, 8: 1, 2: 1}), Counter({4: 5}), Counter({3: 5}), Counter({0: 5}), Counter({7: 5}), Counter({0: 5}), Counter({2: 3, 0: 2}), Counter({7: 3, 9: 1, 8: 1}), Counter({1: 5}), Counter({7: 5}), Counter({3: 4, 6: 1}), Counter({7: 2, 3: 1, 2: 1, 4: 1}), Counter({9: 5}), Counter({7: 5}), Counter({9: 2, 7: 2, 4: 1}), Counter({6: 5}), Counter({2: 5}), Counter({7: 3, 9: 2}), Counter({8: 4, 9: 1}), Counter({4: 5}), Counter({7: 5}), Counter({3: 3, 9: 1, 5: 1}), Counter({6: 5}), Counter({1: 5}), Counter({3: 3, 5: 2}), Counter({6: 5}), Counter({9: 2, 4: 1, 7: 1, 1: 1}), Counter({3: 5}), Counter({1: 5}), Counter({9: 3, 4: 2}), Counter({1: 5}), Counter({1: 3, 7: 2}), Counter({6: 4, 0: 1}), Counter({9: 3, 4: 1, 7: 1})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKrAzu5SXRUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7a0d60f2-8d00-429d-a78c-9f9971726d9f"
      },
      "source": [
        "predictions1 = []\n",
        "for item in final_list1:\n",
        "  predictions1.append(list(item.keys())[0])\n",
        "\n",
        "print(predictions1)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 2, 1, 0, 4, 1, 9, 9, 4, 9, 0, 8, 9, 0, 1, 3, 9, 7, 3, 4, 9, 6, 1, 5, 4, 0, 7, 9, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 1, 1, 1, 7, 4, 1, 5, 5, 1, 8, 4, 4, 6, 3, 5, 5, 0, 0, 4, 1, 9, 1, 7, 2, 9, 9, 7, 4, 8, 4, 3, 0, 7, 0, 0, 7, 1, 7, 3, 3, 9, 7, 9, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 9, 1, 7, 6, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGmcCTrDYdAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8105137d-ae03-48a0-b80e-e7aa90e72c62"
      },
      "source": [
        "z=0\n",
        "for i in range(100):\n",
        "  if(predictions1[i] == test_labels[i]):\n",
        "    z=z+1\n",
        "  \n",
        "    \n",
        "print(z)"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adHfO1r3ZRyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "\n",
        "\n",
        "class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = [classes[i] for i in unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "\n",
        "plot_confusion_matrix(test_labels,predictions1, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}